% -----------------------------------------------
% Template for ISMIR Papers
% 2017 version, based on previous ISMIR templates

% Requirements :
% * 6+n page length maximum
% * 4MB maximum file size
% * Copyright note must appear in the bottom left corner of first page
% * Clearer statement about citing own work in anonymized submission
% (see conference website for additional details)
% -----------------------------------------------

\documentclass{article}
\usepackage{ismir,amsmath,cite,url}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{color}
\usepackage{microtype}


% Title.
% ------
\title{Automatic Sample Detection in Polyphonic Music}

% Note: Please do NOT use \thanks or a \footnote in any of the author markup

% Single address
% To use with only one author or several with the same address
% ---------------
%\oneauthor
% {Names should be omitted for double-blind reviewing}
% {Affiliations should be omitted for double-blind reviewing}

% Two addresses
% --------------
%\twoauthors
%  {First author} {School \\ Department}
%  {Second author} {Company \\ Address}

%% To make customize author list in Creative Common license, uncomment and customize the next line
%  \def\authorname{First Author, Second Author}


% Three addresses
% --------------
\threeauthors
  {First Author} {Affiliation1 \\ {\tt author1@ismir.edu}}
  {Second Author} {\bf Retain these fake authors in\\\bf submission to preserve the formatting}
  {Third Author} {Affiliation3 \\ {\tt author3@ismir.edu}}

%% To make customize author list in Creative Common license, uncomment and customize the next line
%  \def\authorname{First Author, Second Author, Third Author}

% Four or more addresses
% OR alternative format for large number of co-authors
% ------------
%\multauthor
%{First author$^1$ \hspace{1cm} Second author$^1$ \hspace{1cm} Third author$^2$} { \bfseries{Fourth author$^3$ \hspace{1cm} Fifth author$^2$ \hspace{1cm} Sixth author$^1$}\\
%  $^1$ Department of Computer Science, University , Country\\
%$^2$ International Laboratories, City, Country\\
%$^3$  Company, Address\\
%{\tt\small CorrespondenceAuthor@ismir.edu, PossibleOtherAuthor@ismir.edu}
%}
%\def\authorname{First author, Second author, Third author, Fourth author, Fifth author, Sixth author}


\sloppy % please retain sloppy command for improved formatting

\begin{document}

%
\maketitle
%
\begin{abstract}
The term `sampling' refers to the usage of snippets or loops from existing songs or sample libraries in new songs, mashups, or other music productions. Being able to detect sampling in music is beneficial for musicological studies on tracking artist influences geographically and across time. We present a method based on Dynamic Time Warping (DTW) and Non-negative Matrix Factorization (NMF) for the automatic detection of a sample in a set of query songs. The method comprises of two processing steps: first, the DTW alignment path between activations of the query song and reference sample is computed. Second, features are extracted from this path and used to train a Random Forest classifier to detect the presence of the sample. The method is able to identify samples that are pitch-shifted and/or time-stretched. We evaluate this method for sample detection against a new publicly available dataset of real-world sample and song pairs.
\end{abstract}
%
\section{Introduction}
\label{sec:intro}

Sampling, in the context of music composition and production, is the concept of reusing digital recordings in new compositions in a way that it fits in the musical context. In digital sampling, an artist records a segment of a song or sound that they wish to sample, may or may not modify it, and then reuse it (and possibly other recordings) by incorporating it into a new composition. Sampling of audio has become popular in mainstream pop, hip-hop and rap music. 

A sample detection system enables a musicological study of the influence of older artists over newer generation artists by observing sampling patterns over the years.
%It has also gained attention from legal issues in the practice of digital sampling. Section \ref{Motivation} of this paper will discuss the motivation behind research in sample detection. 

Another possible use case of a sample detection system could be to detect plagiarism or copyright infringement. Sampling is legally controversial and determining fair use is largely left to the courthouse. A system that gives an objective measure of the likelihood of a sample being present in an audio file could add weight to either party's argument in a lawsuit.

The algorithm discussed in this paper focuses on solving the problem of detecting the presence of a given sample in a set of songs and also the location of where the sample is most likely present.

% Although sampling is popular as a musical tool, it has not been subject to much research in the domain of Music Information Retrieval. A few works focusing on sampling shall be discussed in Section \ref{related}. The sections that follow will focus mainly on the work that has been done in this paper, discussing the algorithm, the evaluation, and an outline for future work possible.
%
\section{Related Work}
\label{related}

In academia, only a few publications were found that specifically tackled the problem of sample detection. However, there are several parallels that may be drawn from other areas of research that are relevant to sample detection such as cover song detection, audio fingerprinting and remix recognition. The table \ref{comparison} has a brief comparison of audio fingerprinting, cover song detection and sample detection systems.

\begin{table*}[]
\centering
\caption{Comparison Table of Related Work}
\label{my-label}
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{1}{|l|}{}                                                      & \textbf{Audio Fingerprinting}                                                                      & \textbf{Cover Song Detection}                                                                                                   & \textbf{Sample Detection}                                                                                                        \\ \hline
\begin{tabular}[c]{@{}c@{}}Similarity of query \\ to reference\end{tabular} & \begin{tabular}[c]{@{}c@{}}Exact audio is detected, with \\ some degradation possible\end{tabular} & \begin{tabular}[c]{@{}c@{}}Cover is not exactly the same \\ audio as the reference\end{tabular}                                 & \begin{tabular}[c]{@{}c@{}}Exact sample is present in reference, \\  with or without effects \end{tabular}                  \\ \hline
\begin{tabular}[c]{@{}c@{}}Addition of extra \\ audio tracks\end{tabular}   & \begin{tabular}[c]{@{}c@{}}Query audio isn't mixed \\ with other audio tracks\end{tabular}         & \begin{tabular}[c]{@{}c@{}}Cover is usually a linear \\ performance of the reference \\ with possible artistic or instrumental changes\end{tabular} & \begin{tabular}[c]{@{}c@{}}Sample could be present in a \\ mixture of several other \\ audio tracks in the reference\end{tabular} \\ \hline
\end{tabular}
\end{table*}

\subsection{Audio Fingerprinting}

Audio fingerprinting refers to the method of extracting content-based signatures from audio \cite{cano2005review}. It is most commonly used in content-based music retrieval systems, like Shazam\footnote{https://www.shazam.com/}.
Van Balen proposed the use audio fingerprinting for sample detection \cite{van2011automatic}. He used a popular fingerprinting by Wang \cite{wang2003industrial}, in an implementation by Ellis \cite{ellisfinger}. 
% The implementation was adapted to this task by: 
% \begin{enumerate*}
% \item Enabling the system to handle longer audio queries.
% \item Optimizing the parameters for landmark matching.
% \end{enumerate*}

Fingerprinting is a good choice for building systems that are robust against attacks such as pitch shifting or time stretching of audio, but in the case of sample detection, a sample is usually one component in a mixture of audio. Audio fingerprinting detects the exact audio but wouldn't perform well when the audio is mixed and masked by other audio signals.

\subsection{Cover Song Detection}
Cover song detection is the task of recognizing whether a given reference track has a cover song in a set of test tracks\cite{Ellis2007Cover,serracover,bertin2011large}.
In cover song detection, covers may also be transposed or pitch-shifted and may vary in tempo from the original song. Dynamic Time Warping (DTW) \cite{berndt1994using} is often used to make these systems time invariant and this work uses the same. The difference lies in the fact that covers are renditions of a musical piece, while samples are snippets of audio which are usually a part of the mix overlaid with a lot of other instruments and sounds that are original to the new song.

Evaluating cover song detection systems and a sample detection system is highly similar. Both have a test/reference pair which is then categorized as a positive or negative match with a confidence measure. 
\subsection{Remix Recognition}

Work done in remix recognition by Casey et al. \cite{caseyRemix} draws inspiration from a method for web crawling called `shingling' which utilizes a stream of text position-based features to detect if a document has already been crawled before. They snip an audio track into 4 second `shingles' and search in a set of similarly snipped test tracks using popular low-level audio features such as MFCCs and pitch-class profiles. In sample detection, such a system wouldn't work because the features would capture information of the whole mix instead of just the sample.

\subsection{Non-negative Matrix Factorization-based Approach}

Dittmar et al. outlined three kinds of plagiarism in music, one of them being sample plagiarism \cite{dittmar2012audio}. They make use of Non-negative Matrix Factorization (NMF) to learn the spectral templates from the sample and detect the presence of these templates in the suspect audio. Correlating the activations from the sample and the song gives the likelihood of plagiarism.

While the authors provide an outline for sample detection, they do not offer a very detailed description of the specific algorithm. Sample detection, as a task in music information retrieval, hasn't yet been well defined in terms of methodology or evaluation. Publications are few and datasets related to sampling are non-existent or proprietary.


\section{Sample Detection Algorithm}
\label{algo}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{block_diagram.png}
\caption{Block diagram showing the flow of the algorithm}
\label{fig_block}
\end{figure}

The algorithm presented in this paper is based on the work by Dittmar et al. \cite{dittmar2012audio} The reason we chose to go with an NMF-based approach to sample detection is because of its prevalence in source separation tasks \cite{virtanen2007monaural}. The task of sample detection is similar to a source identification problem where the sample is one of the sources present in the mix. The block diagram in Fig. \ref{fig_block} shows the high level processing steps of the algorithm.

\subsection{Non-Negative Matrix Factorization}

NMF is a widely popular algorithm in unsupervised learning with applications in recommendation systems\cite{koren2009matrix} and signal processing\cite{lee1999learning}. NMF factorizes a signal $V \in \mathbb{R}^{M\times N}$ into a template matrix $W \in \mathbb{R}^{M\times K}$ and an activation matrix $H \in \mathbb{R}^{K\times N}$.
\[ V = W\cdot H\]
If $V$ is the magnitude spectrogram, $W$ contains the $K$ spectral or harmonic information in $V$ while $H$ contains temporal information about each corresponding spectral components in the template matrix \cite{smaragdis2003non}.

Given the original sample, after RMS normalizing, downmixing and downsampling audio to 22050Hz, we compute its magnitude spectrogram(block size 4096, hop size 1024 samples). Similarly, we preprocess and compute the magnitude spectrogram of the song, which may or may not contain the sample.
Using NMF, an original sample spectrogram will be factorized into its $K$ templates, $W_\mathrm{o}$, and activation matrix, $H_\mathrm{o}$. A sample, used in a song, may be thought of as a source in a mixture of other sources in the song in question. Using the extracted templates $W_\mathrm{o}$ from the original sample, we can obtain the corresponding activations, $H_\mathrm{s}$, in the song mixture by performing a partially fixed NMF\cite{wu2015drum} where the templates $W_\mathrm{o}$ are fixed and the mixture templates $W_\mathrm{m}$ are iteratively learned. In the subsequent analysis, we are only interested in the activations $H_\mathrm{s}$ corresponding to $W_\mathrm{o}$ since they indicate the presence of the sample in the song. Given that the sample wasn't pitch shifted or time-stretched, a cross-correlation between the activations $H_\mathrm{o}$ and $H_\mathrm{s}$ can be computed and peaks would show the presence of the sample. The 2-d cross-correlation between corresponding activation functions can be aggregated across the $K$ dimensions and figure \ref{fig1} shows results when the geometric mean was used for aggregation, for a true positive and a true negative detection.

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{corr.png}
\caption{Geometric mean of correlation functions for when sample is present twice (above) and sample is absent (below)}
\label{fig1}
\end{figure}

\subsubsection{Pitch-shifting}

Pitch-shifting is a very common effect applied to samples before being used by artists in their own composition. It refers to the process of changing the pitch of the original sample up or down. In case of pitch-shifting, the sample templates $W_\mathrm{o}$ will no longer be the bases in the mixture since the spectral content has shifted logarithmically in the frequency scale by the pitch-shift factor. In order to account for pitch-shifting, we construct new sets of spectral templates by scaling the frequency axis of the templates with a number of hypothesized pitch-shift factors and create an extended $W_\mathrm{o}$ matrix. Now, a partially fixed NMF will be able to extract activations corresponding to each set of pitch-shifted templates and these may be compared to the activations from the original sample.

\subsubsection{Time-stretching}

Time-stretching is another common effect used in sampling. Artists most often change the speed of the sample in order to match their own song's tempo. In the case where a sample is time-stretched, the activations from the song will be similarly stretched and we can no longer use a cross-correlation since the activations will no longer align at a point where the sample is present.

In such a scenario, Dynamic Time Warping is used to align the activations $H_\mathrm{o}$ with the activations $H_\mathrm{s}$ at a start frame $f$ in the song for each pitch-shift factor. A distance matrix is constructed using the pair-wise 2-d correlation between the $K$ dimensional activations. 
\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{distmat.png}
\caption{Distance matrix computed between activations in the case where a sample is looped}
\label{fig2}
\end{figure}

This problem is now a subsequence search for the sample activations $H_\mathrm{o}$ within the series of activations corresponding to the sample templates in the song, $H_\mathrm{s}$. We compute the cost matrix using DTW. The cost matrix is initialized by accumulating the distance matrix along the direction of sample only. The accumulated cost of alignment is an indicator of whether a sample is present at a particular frame in time or not. 

\subsubsection{NMF Rank Selection}
\label{nmfrank}

We need to select parameters for the rank $K$ of the sample spectrogram based on how many spectral templates can be used to approximate the sample. Similarly, while doing the partially fixed NMF, we need to define a rank to approximate the remaining mixture in the song so that the fixed sample templates are able to properly model the presence of the sample and reflect that in the activations.

Different songs will require different ranks for accurately approximating and factorizing the magnitude spectrograms with a low reconstruction error. In the current algorithm, fixed ranks are chosen empirically for both, the sample NMF and the mixture NMF. The rationale behind this is that for this task, a perfect reconstruction is not required. The templates and activations may be treated as intermediate features that identify the sample and regardless of whether the templates are able to combine linearly to reconstruct the original spectrogram, if the sample is used in a song, the same templates should produce a similar set of activations. 

A possible extension could be to analyze the audio separately as a pre-processing step to obtain an approximate `complexity' of the audio and set variable ranks based on the complexity of the spectrogram to be modeled. 

\subsubsection{Activation Normalization}

In order for a correct sample detection, it is necessary to properly normalize the sets of activations extracted from the sample and the query song. Each set of activations is normalized by the absolute maximum across all the $K$ activations across time. The idea is to preserve relative activation strengths for all the spectral templates of the sample.

\[H_{normalized} = \frac{H}{max(H^{k}_{t}: k\in[1,K], \forall t )}\]

Note that to account for pitch-shifting, there are $n$ sets of activations, where $n$ is the number of hypothesized pitch-shift factors. This normalization is applied to each of the $n$ sets of activations. 


\subsection{Feature Extraction}

Before feature extraction, we first decided which pitch-shift factor is applied to the sample. For each set of activations corresponding to the different pitch-shifted templates, the minimum cost DTW path is computed. The global minimum among these paths is used to determine which pitch-shift is applied and further computations are done using the corresponding activation matrix.

To detect whether a sample is present in a song, DTW costs are computed for alignment paths backtracking from all end frames in the song and normalized by the length of the path. This mapping for every end frame in the song to the DTW cost for the path ending at that frame is called the DTW cost function. Figure \ref{fig3} shows an example of this mapping. Ideally, the end frame where the sample ends will be a local or global minimum in the function.

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{DTWcost.png}
\caption{DTW cost function; Minima indicate the end of the sample}
\label{fig3}
\end{figure}

% \subsubsection{Detection}



Using an absolute threshold on the DTW cost to detect a sample is not meaningful because a low alignment cost in one song might not be a low cost in another song. The reason is that the mixing factor of samples in different songs may be different. Some might have a quiet signal at the sample sample whereas in other songs a sample might be heavily overlaid with other sounds. This leads to varying strength in activations across different song and sample pairs. 
% Hence it is imperative to normalize activations across songs and samples. We discuss how normalization is done in Sect. \ref{dis}

Another feature obtained from the DTW is the location in the song at which an alignment path starts. Intuitively, given that a sample is present, the DTW backtracking path for end frames in the neighborhood of the exact location where the sample ends would also, after some DTW steps, merge into the optimal alignment path. Therefore, mapping the end points to the start points, we would observe a constant start point value for end points in the neighborhood of the location of the sample. This mapping is called the DTW path start function. Figure \ref{fig4} shows one example of this function. A flat step in this function refers to ending frames that map to the same start point in the song after DTW.

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{DTWpath.png}
\caption{DTW path start function; Longer steps indicate sample}
\label{fig4}
\end{figure}

A valid assumption for each step in this function is that the local minimum of the DTW cost function should be considered as a candidate for sample detection. Hence for each song and sample pair, each unique start location in the DTW path start function is a candidate for classification and we extract the following features from the two aforementioned mappings as well as the DTW paths that were computed.

\subsubsection{DTW Cost: 3 features}
We extract the local minimum of the DTW cost for each end point corresponding to the unique start location. Along with the minimum, we also compute the mean and standard deviation of the cost over the set of points that map to the current step. The costs are normalized by the DTW path length.

\subsubsection{Path Features: 7 features}
After extracting the local minimum DTW cost, we also extract the length and slope of the path for the minimum cost. In addition, we compute the mean deviation of the path's slope from a straight line. In this discretized space, the deviation is computed using euclidean geometry. The distance matrix's first point is chosen as origin. The line joining the start point and end point of the path is computed and for every other point in the path, we accumulate the perpendicular distance from the straight line and normalize by the length of the path. The final features used are the slope and slope deviation of the minimum cost path, mean and standard deviation of path slopes within the step, the path length, mean and standard deviations of all path lengths within the step.

In addition, we use the length of the step in the DTW path start function corresponding to the current unique start location. This gives us a 11-dimensional feature space.

% \begin{enumerate}
% \item DTW cost: Local minimum in the DTW cost function.
% \item Slope deviation: Value at the index of minimum cost.
% \item Length of path for minimum cost.% Normalized by length of sample.
% \item Slope of path for minimum cost.
% \item Length of step in the DTW path start function corresponding to the current start location. %Normalized by length of the sample.
% \item Mean of the local cost for the current step.
% \item Standard deviation of the local cost for the current step.
% \end{enumerate}

% The DTW is also used to compute a feature we define as `slope deviation'. The slope deviation is another path feature which computes the deviation of the path from the average slope of that path normalized by the path length. This is computed using the perpendicular euclidean distance of every point in the path from the line joining the start and end points that that path.


\subsection{Classification}
\label{class}

Given the set of features extracted for each unique start location, the task at hand is a simple binary classification. The definition of an instance or a data point $x$ in our case is: Every unique start location in the DTW path start function. The classifier $f(x)$ needs to decide whether a sample is present at the location denoted by $x$.

A random forest classifier was chosen for this task \cite{breiman2001random}. The input is a 11-dimensional feature vector described above and it classifies each datapoint as a location where the sample is present or not with a probability of the instance being in each class. We use an ensemble of 200 decision trees and the number of features chosen for each decision split is 4.

% \begin{algorithm}
% \begin{enumerate}
% \item Compute the magnitude spectrogram of the original sample, $X_o$ and the song, $X_s$. 
% \item Compute the template $B_o$ and the activations $G_o$ from the sample spectrogram $X_o$ using NMF. The rank $k$ may be set based on the signal.
% \item Apply NMF on the song spectrogram $X_s$, but this time, make use of the templates $B_o$ in addition to other mixture templates while computing the NMF. This is called partially-fixed NMF.
% \item Correlate the activations $G_s$ corresponding to $B_o$ for the song spectrogram $X_s$ with the originally computed activations for the original sample $G_o$. In the ideal case, a correctly detected sample would mean that both the activations have a very high correlation at the position of occurrence as compared to other lags in time.
% \item Currently, return a positive match if peaks in the correlation function are greater than $0.6$. Figures \ref{fig1} and \ref{fig2} show the geometric means of correlations between 6 activations for the sample and the song, one for a true positive and one for a true negative.
% \end{enumerate}
% \caption{{\bf Non-negative Matrix Factorization-based Sample Detection} \label{Algorithm3}}
% \end{algorithm}

\section{Evaluation}
\label{eval}

\subsection{Dataset}
A dataset was compiled using whosampled.com\footnote{www.whosampled.com, last accessed: 1/22/2017} for this task. Whosampled is a website that aggregates information about songs that sample or cover other songs. The audio was downloaded using web services from streaming websites like Youtube or Dailymotion.

80 samples were selected with original songs from influential artists like James Brown, Stevie Wonder, Michael Jackson, and other artists. The songs that used these samples are from Hip-Hop, Pop and Rap genres in general with a few exceptions. The samples in this dataset cover several variations of sampling such as: one-shot samples of musical snippets or voice samples, looped drums and looped melodies. The longest sample is 25 seconds, the shortest is half a second and the average length of the samples is 4.5 seconds. The total number of sampling instances is 876.

For each original song, the start and end time of the segment that was sampled is manually annotated. For each annotated sample, in the corresponding song that sampled it, all start locations of the sample are annotated. All annotation is done using Sonic Visualizer \cite{SonicVisualiser}. In addition, the pitch-shift factor of the sample in the song are annotated.

These annotations including the song names and URLs for obtaining the audio have been made available publicly.\footnote{www.github.com/placeholder\_repo}

\subsection{Experiments}

In our experiments, we chose 10 songs for each of the samples in our dataset to detect sampling. Of the 10, the sample is only present in one song and the remaining 9 songs are randomly sampled from the set of songs that don't contain the sample. This gives us $80\times10 = 800$ sample-song pairs.

To evaluate the classifier, the first 50 samples from dataset were chosen as the training set. Further, problematic samples were identified where there were no diagonals observed in the distance matrix. These were pruned from the subset. Section \ref{def} will discuss these problematic samples. Experiments are carried out using both: the full training set and the pruned training set.

In the training set, for each sample and song pair, all unique start points after feature extraction were labeled as `0' or `1' based on whether a sample is present. In order to achieve this, the ground truth of the time instants of where samples were present are used. Any start point within a 1 second window of the ground truth annotation is labeled `1'. In some instances there were multiple start points within the 1 second tolerance window. To break these ties, instead of choosing the closest start location, the location that had the minimum cost DTW path was labeled `1' and the rest are labeled `0'. The reason for doing this is that, upon observation, it was found that some of these candidates were false positives with high DTW costs.

10-fold cross-validation was used with this data to obtain the training accuracy.

For testing, the remaining 30 samples are used. For each of the 300 sample-song pairs, features are extracted and the predictions are obtained for each candidate sample location. For the sample-song pairs that contain the sample, the ground truth annotations are obtained and any positive detection within a 1 second tolerance window is classified as a true positive. If multiple positive detections are obtained in the tolerance window, all but the closest detection are classified as false positives. The remaining positive detections are also false positives. For sample-song pairs that don't contain the sample, any positive detections are obviously false positives. We report the precision, recall and f-measure for the sample location detection. We refer to these as micro-accuracy measures.

In addition to the micro-accuracy measures, we also report the song-level sample detection precision, recall and f-measure for a binary classifier for classifying whether a song contains a given sample or not. We refer to these as macro-accuracy measures.

\section{Results}

% \section{Discussion}
% \label{dis}

% While the algorithm discussed here seems simple and effective in solving the problem, there were several interesting nuances in the topic that were overlooked in previous work by Dittmar et al, as well as our initial implementation of the algorithm. This section will discuss some of these in detail.

% \subsection{DTW computation}

% In the current state, the distance matrix is computed using a correlation distance across the rank of the activation matrices. This kind of distance measure, however, doesn't account for any sparseness which is very likely in the NMF output. Distances between elements that are 0 shouldn't affect the overall distance as much as distances where the activations are higher and more similar. A new distance measure might be required to take into account this asymmetry in activation distances.

% \subsection{Normalization}

% The topic of normalization is one of the biggest issues that we faced and are still facing while devising this algorithm. The first step where normalization begins to affect the results is the normalization of the activations. Without normalizing the activations, the scale of the two sets of activations might be very different and any distance computation will be meaningless. Therefore, we currently normalize the activation with the maximum value in the activations for all templates. This makes sense against normalizing with the maximum per template because we want to preserve relative activations across the whole rank.

% The features that we use for the classification also need to be normalized appropriately in order to develop a generalized model. In the current state, the costs are normalized by the alignment path length, the length of the steps in the DTW path start function is normalized by the length of the sample in frames, the slope deviation is also normalized by the path length. While the choice of the alignment path for normalization makes sense, incorporating the time stretch factor, could be another approach to normalization.

% The discussion about NMF rank selection may also fall under the topic of normalization. If the parameters for the rank may be set correctly then it is possible that we can achieve better normalization of the final features across all samples and songs which will make a trained model more generalized.

% \subsection{Problematic Samples}

% While labelling the data before training or testing the classifier, it was observed that some samples weren't showing diagonal paths of low cost in the distance matrix unlike most of the other samples which were used for training and testing. Upon observation of these samples, it was noted that some of them were very short, quiet, were drum loops or had effects applied to them. These observations may or may not be the reason that the NMF activations distances aren't able to reveal the presence of the sample.

% Another possible explanation for this could be incorrectly annotated pitch-shift factors which will throw off the partially fixed NMF step of the algorithm. Further research needs to be done focusing on these samples to determine what is causing this.

\section{Future Work}


\section{Conclusion}

In this work, an algorithm for sample detection based on NMF and DTW, which is robust against pitch-shifting and time-stretching is presented. A framework for research in sample detection is described and a dataset a specifically created for this task. The paper describes a promising algorithm that uses NMF and DTW to solve the problem which is currently evaluated against the given dataset. The results from the evaluation are encouraging and approaches to further improve the algorithm are proposed by way of normalization and pre-processing.

% For bibtex users:
\newpage
\bibliography{ISMIRtemplate}

% For non bibtex users:
%\begin{thebibliography}{citations}
%
%\bibitem {Author:00}
%E. Author.
%``The Title of the Conference Paper,''
%{\it Proceedings of the International Symposium
%on Music Information Retrieval}, pp.~000--111, 2000.
%
%\bibitem{Someone:10}
%A. Someone, B. Someone, and C. Someone.
%``The Title of the Journal Paper,''
%{\it Journal of New Music Research},
%Vol.~A, No.~B, pp.~111--222, 2010.
%
%\bibitem{Someone:04} X. Someone and Y. Someone. {\it Title of the Book},
%    Editorial Acme, Porto, 2012.
%
%\end{thebibliography}

\end{document}
